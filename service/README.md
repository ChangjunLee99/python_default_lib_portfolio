# MCP (Multi-Client Processing) 서비스

MCP 서비스는 다양한 LLM 클라이언트를 활용하여 사용자의 쿼리를 자동으로 분석하고 적절한 작업을 수행하는 지능형 웹 서비스입니다.

## 설치 방법

1. 필요한 패키지 설치:
```bash
pip install -r requirements.txt
```

2. 서비스 실행:
```bash
python mcp_service.py
```

## API 엔드포인트

### 쿼리 처리 (/api/query)
- POST 요청으로 쿼리를 전송하면 자동으로 의도를 분석하고 적절한 작업을 수행
```json
{
    "query": "사용자 쿼리"
}
```

## 지원하는 쿼리 유형

### 1. 파일 처리
- 예시:
  - "test.txt 파일의 내용을 분석해줘"
  - "이 파일을 요약해줘: /path/to/file.txt"

### 2. 검색
- 예시:
  - "파이썬이란 무엇인가요?"
  - "최신 AI 기술에 대해 알려줘"

### 3. 채팅
- 예시:
  - "안녕하세요"
  - "오늘 날씨 어때요?"

### 4. 예약
- 예시:
  - "내일 오후 2시에 회의 일정을 잡아줘"
  - "다음 주 월요일 아침 9시에 알림 설정해줘"

## 지원하는 LLM 클라이언트
- Ollama
- Gemini
- OpenAI

## 환경 설정
- 기본 포트: 5000
- 호스트: 0.0.0.0
- 디버그 모드: 활성화 